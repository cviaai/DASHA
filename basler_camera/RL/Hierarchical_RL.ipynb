{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CIG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.spaces import Box, Discrete, Tuple, MultiDiscrete\n",
    "import logging\n",
    "import random\n",
    "from PIL import Image\n",
    "from pypylon import pylon\n",
    "from ray.rllib.env import MultiAgentEnv\n",
    "import ray\n",
    "from ctypes import *\n",
    "import os\n",
    "from ray import tune\n",
    "from ray.tune import function\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.rllib.agents.ppo import PPOTrainer, PPOTFPolicy, PPOTorchPolicy\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import error\n",
    "from gym.utils import closer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from ray.tune.logger import pretty_print\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "from gym import error\n",
    "from gym.utils import closer\n",
    "from gym import spaces\n",
    "import time\n",
    "from matplotlib import cm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from torch import nn\n",
    "import imquality.brisque as brisque\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera_Env(gym.Env):\n",
    "    def __init__(self, camera, \n",
    "                       Width = 417,\n",
    "                       Height = 404):\n",
    "        \n",
    "        self.camera = camera\n",
    "        self.camera.AcquisitionFrameRateAbs.Value = 10\n",
    "        self.camera.GainRaw.Value = 36\n",
    "        self.camera.AcquisitionMode.SetValue('Continuous')\n",
    "        self.Width = Width\n",
    "        self.Height = Height\n",
    "        self.camera.Width.Value = Width\n",
    "        self.camera.Height.Value = Height\n",
    "        print(self.camera.Width.GetValue(), self.camera.Height.GetValue())\n",
    "        # see https://github.com/basler/pypylon/blob/master/samples/opencv.py\n",
    "        img = pylon.PylonImage()\n",
    "        self.converter = pylon.ImageFormatConverter()\n",
    "        # converting to opencv bgr format\n",
    "        self.converter.OutputPixelFormat = pylon.PixelType_BGR8packed\n",
    "        self.converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned\n",
    "        \n",
    "        \n",
    "        self.range_ex_time = np.concatenate((np.arange(1e3, 45e3, 1000), \n",
    "                                             np.arange(50e3, 500e3, 5000), \n",
    "                                             np.arange(600e3, 900e3, 50000), \n",
    "                                             np.arange(100e4, 500e4, 500000))).astype(np.int64)\n",
    "        \n",
    "        number_of_actions = len(self.range_ex_time)\n",
    "        print(number_of_actions)\n",
    "        \n",
    "        self.action_space = Discrete(number_of_actions)\n",
    "        # image\n",
    "        self.observation_space = Box(0, 1, (2048,))#(len(np.zeros((404, 417, 3)).flatten()),))\n",
    "#         self.observation_space = Box(low=0, \n",
    "#                                     high=255, \n",
    "#                                     shape=(Height, Width, 3),\n",
    "#                                     dtype = np.uint8)\n",
    "        \n",
    "        print('---------------camera env init-------------------')\n",
    "        \n",
    "    def grab_image(self):\n",
    "        # see https://github.com/basler/pypylon/blob/master/samples/opencv.py\n",
    "        self.camera.StartGrabbing()\n",
    "        while 1:\n",
    "            grabResult = self.camera.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)\n",
    "            if grabResult.GrabSucceeded():\n",
    "                # Access the image data\n",
    "                image = self.converter.Convert(grabResult)\n",
    "                image = image.GetArray()\n",
    "                break\n",
    "        self.camera.StopGrabbing()\n",
    "        return image\n",
    "    \n",
    "    def basler(self, action):  \n",
    "        ExposureTimeRaw = int(self.range_ex_time[action])\n",
    "        #print('ExposureTimeRaw:', ExposureTimeRaw) \n",
    "        self.camera.ExposureTimeRaw.Value = ExposureTimeRaw\n",
    "        #time.sleep(5) \n",
    "        \n",
    "    def check_hist(self, img):\n",
    "        #print('check img')\n",
    "        hist , bin_edges = np.histogram(np.array(img).ravel())\n",
    "        max_value_bin = bin_edges[np.argmax(hist)]\n",
    "        if max_value_bin > 50 and max_value_bin < 150:\n",
    "            pic_ok = True\n",
    "        else:\n",
    "            pic_ok = False\n",
    "        return pic_ok\n",
    "    \n",
    "    def reset(self):\n",
    "        self.camera.ExposureTimeRaw.Value = 20000\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.basler(action)\n",
    "#         self.lens_environment.lens_movement(46.0)\n",
    "        img = self.grab_image()\n",
    "        done = self.check_hist(img)\n",
    "        if done:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        return img, reward, done, {}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lens_Env(gym.Env):\n",
    "    def __init__(self, camera,\n",
    "                        Height = 404, \n",
    "                         Width = 417):\n",
    "        \n",
    "        # corning lib\n",
    "        self.lib = cdll.LoadLibrary(r\"C:\\Users\\CIG\\Documents\\MATLAB\\ComCasp64.dll\")\n",
    "        #Check if Maxim driver dll is loaded\n",
    "        eCOMCaspErr = getattr(self.lib,'Casp_OpenCOM')\n",
    "        print('eCOMCaspErr:', eCOMCaspErr(), self.lib.Casp_OpenCOM())\n",
    "        \n",
    "        self.Width = Width\n",
    "        self.Height = Height\n",
    "        \n",
    "        self.action_space = MultiDiscrete([69, 99])\n",
    "        # image\n",
    "        self.observation_space = Box(0, 1, (2048, ))#(len(np.zeros((404, 417, 3)).flatten()),))\n",
    "#         self.observation_space = Box(low=0, \n",
    "#                                             high=255, \n",
    "#                                             shape=(self.Height, self.Width, 3),\n",
    "#                                             dtype = np.uint8)\n",
    "        self.camera_env = Camera_Env(camera)\n",
    "        print('---------------lens env init-------------------')\n",
    "    \n",
    "    def lens_movement(self, action):\n",
    "        x = c_double(action)\n",
    "        self.lib.Casp_SetFocusVoltage(x)\n",
    "        #time.sleep(2)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.lens_movement(46.0)\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.lens_movement(action)\n",
    "        img = self.camera_env.grab_image()\n",
    "        return img, -1, False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaslerEnv(MultiAgentEnv):\n",
    "    def __init__(self, \n",
    "                       Width = 417,\n",
    "                       Height = 404,\n",
    "                       threshold = 25,\n",
    "                       filepath = r'D:\\rl_noise'):\n",
    "        \n",
    "        self.camera = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateFirstDevice())\n",
    "        self.camera.Open()\n",
    "\n",
    "        self.basler_env = Camera_Env(self.camera)\n",
    "        self.corning_env = Lens_Env(self.camera)\n",
    "        \n",
    "        # yolo\n",
    "        self.model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', \n",
    "                                         force_reload=True, \n",
    "                                         pretrained=True)\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        self.filepath = filepath\n",
    "        self.n = 0\n",
    "        self.control_hla = 1\n",
    "        \n",
    "        \n",
    "        self.resnet152 = models.resnet152(pretrained=True)\n",
    "        modules=list(self.resnet152.children())[:-1]\n",
    "        self.resnet152=nn.Sequential(*modules)\n",
    "        for p in self.resnet152.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        print(True)\n",
    "        \n",
    "    def take_features(self, img):\n",
    "        preprocess = transforms.Compose([\n",
    "                            transforms.Resize(256),\n",
    "                            transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "        \n",
    "        image = Image.fromarray(np.uint8(img)).convert('RGB')\n",
    "        input_tensor = preprocess(image)\n",
    "        input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "        \n",
    "        # Run through the convolutional layers and resize the output.\n",
    "        features_output = self.resnet152(input_batch)\n",
    "        classifier_input = features_output.view(1, -1)\n",
    "        \n",
    "        return classifier_input.cpu().detach().numpy()[0]\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        #print('reset')\n",
    "        self.basler_env.reset()\n",
    "        self.corning_env.reset()\n",
    "        \n",
    "        self.steps_remaining_at_level = None\n",
    "        self.num_high_level_steps = 0\n",
    "        \n",
    "        self.low_level_agent_id = \"low_level_{}\".format(self.num_high_level_steps)\n",
    "        \n",
    "        obs = self.basler_env.grab_image()\n",
    "        #print('reset|grab img')\n",
    "        feature_obs = self.take_features(obs)\n",
    "        \n",
    "#         im = Image.fromarray(obs)\n",
    "#         filename = self.filepath + '\\Start' + \"\\img_%s.png\" % (str(self.n))\n",
    "#         im.save(filename)\n",
    "        \n",
    "        self.n+=1\n",
    "        \n",
    "        if self.n %2000 ==0:\n",
    "            self.n = 0\n",
    "        \n",
    "        \n",
    "        return {\"high_level_agent\": feature_obs,}\n",
    "    \n",
    "    def focus_value(self, img):\n",
    "        # Calculate the gradient\n",
    "        sobelx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1 , 0, ksize=5)\n",
    "        sobely = cv2.Sobel(np.float32(img),cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "        abs_sobel_x = cv2.convertScaleAbs(sobelx) # converting back to uint8\n",
    "        abs_sobel_y = cv2.convertScaleAbs(sobely)\n",
    "        #print(abs_sobel_x )\n",
    "\n",
    "        # Combine the two gradients with equal weight\n",
    "        dst = cv2.addWeighted(abs_sobel_x,0.5,abs_sobel_y,0.5,0)\n",
    "        #print(dst)\n",
    "\n",
    "        # Calculate the average gradient for the image\n",
    "        # I convert it to a numpy array for ease of calculation\n",
    "        return pl.asarray(dst).mean()\n",
    "    \n",
    "    def find_class(self, results, obj = 'car'):\n",
    "        len_of_class = len(results.pred)\n",
    "        pred_class = [int(results.pred[0][i].numpy()[5]) for i in range(len(results.pred[0]))]\n",
    "        #list_of_yolo_classes = list(zip(results.names, range(0, len(results.names))))\n",
    "        pred_names = [results.names[i] for i in pred_class]\n",
    "        if obj in pred_names:\n",
    "            index = pred_names.index(obj)\n",
    "            return results.pred[0][index].numpy()\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "    \n",
    "    def step(self, action_dict):\n",
    "        if \"high_level_agent\" in action_dict:\n",
    "            return self._high_level_step(action_dict[\"high_level_agent\"])\n",
    "        else:\n",
    "            return self._low_level_step(list(action_dict.values())[0])\n",
    "        \n",
    "    \n",
    "    def _high_level_step(self, action):\n",
    "        \n",
    "        self.action_main = action\n",
    "        \n",
    "#         logger.debug(\"High level agent action\".format(action))\n",
    "        \n",
    "        #self.obs_camera, reward_camera, done_c, _ = self.basler_env.step(action)\n",
    "        self.basler_env.basler(action)\n",
    "        #self.corning_env.lens_movement(46.0)\n",
    "        self.obs_camera = self.basler_env.grab_image()\n",
    "        self.done_camera = self.basler_env.check_hist(self.obs_camera)\n",
    "        \n",
    "        self.steps_remaining_at_level = 10\n",
    "        self.num_high_level_steps += 1\n",
    "        self.low_level_agent_id = \"low_level_{}\".format(self.num_high_level_steps)\n",
    "        \n",
    "        feature_obs = self.take_features(self.obs_camera)\n",
    "        obs = {self.low_level_agent_id: feature_obs}\n",
    "        rew = {self.low_level_agent_id: 0}\n",
    "        \n",
    "        done = {\"__all__\": False}\n",
    "        \n",
    "        return obs, rew, done, {}\n",
    "    \n",
    "    def _low_level_step(self, action):\n",
    "        \n",
    "        action_lens_coarse = 0\n",
    "        action_lens_fine = action[1]\n",
    "        if action[0] < 24:\n",
    "            action_lens_coarse = 24\n",
    "        else:\n",
    "            action_lens_coarse = action[0]\n",
    "        action_lens = float(\"%s.%s\"% (str(action_lens_coarse), str(action_lens_fine)))\n",
    "        \n",
    "#         logger.debug(\"Low level agent step {}\".format(action_lens))\n",
    "        done = {\"__all__\": False}\n",
    "        if self.done_camera == True:\n",
    "            self.control_hla = 1\n",
    "            self.steps_remaining_at_level -= 1\n",
    "\n",
    "            obs_lens, reward_lens, done_lens, _ = self.corning_env.step(action_lens)\n",
    "            feature_obs = self.take_features(obs_lens)\n",
    "            obs = {self.low_level_agent_id: feature_obs}\n",
    "\n",
    "            #rew = {self.low_level_agent_id: 1}\n",
    "            prediction_yolo = self.model_yolo(obs_lens)\n",
    "            final_result_yolo = self.find_class(prediction_yolo)\n",
    "\n",
    " \n",
    "            flag = False #for save img information\n",
    "            if final_result_yolo.size == 0:\n",
    "                rew = {self.low_level_agent_id: 1 - 1*(10 - self.steps_remaining_at_level)}\n",
    "                if self.steps_remaining_at_level == 0:\n",
    "                    done[self.low_level_agent_id] = True\n",
    "                    rew[\"high_level_agent\"] = 0.5\n",
    "                    obs[\"high_level_agent\"] = feature_obs\n",
    "#                 else:\n",
    "#                     rew = {self.low_level_agent_id: -100 + 1*(10 - self.steps_remaining_at_level)}\n",
    "\n",
    "            else:\n",
    "                image = Image.fromarray(obs_lens)\n",
    "                image = image.crop((final_result_yolo[0], \n",
    "                                 final_result_yolo[1], \n",
    "                                 final_result_yolo[2], \n",
    "                                 final_result_yolo[3]))\n",
    "                foc_value = round(brisque.score(image), 2)#self.focus_value(image)\n",
    "                \n",
    "                if foc_value <= self.threshold:\n",
    "                    rew = {self.low_level_agent_id: 1}\n",
    "                    done[\"__all__\"] = True\n",
    "                    logger.debug(\"high level final reward {}\".format(1))\n",
    "                    flag = True\n",
    "                    rew[\"high_level_agent\"] = 1\n",
    "                    obs[\"high_level_agent\"] = feature_obs\n",
    "                    \n",
    "                    im = Image.fromarray(obs_lens)\n",
    "                    filename = self.filepath + '\\End' + \"\\img_%s_%s_%s.png\" % (str(self.action_main),\n",
    "                                                                      str(action_lens), \n",
    "                                                                      str(foc_value))\n",
    "                    im.save(filename)\n",
    "                    \n",
    "                elif self.steps_remaining_at_level == 0 and foc_value > self.threshold:\n",
    "                    \n",
    "                    rew = {self.low_level_agent_id: -10}\n",
    "                    done[self.low_level_agent_id] = True\n",
    "                    rew[\"high_level_agent\"] = 0.5\n",
    "                    obs[\"high_level_agent\"] = feature_obs\n",
    "                    \n",
    "                elif self.steps_remaining_at_level != 0 and foc_value > self.threshold:\n",
    "                    rew = {self.low_level_agent_id: - 0.001*(foc_value - self.threshold)**2}\n",
    "                else:\n",
    "                    print('new case|foc value:',foc_value, \n",
    "                          'steps_remaining_at_level:', self.steps_remaining_at_level)\n",
    "                    \n",
    "#             path = r'D:\\rl_noise' \n",
    "#             im = Image.fromarray(obs_lens)\n",
    "#             filename = path + \"\\img_%s_%s_%s.png\" % (str(self.action_main),\n",
    "#                                                       str(action_lens), \n",
    "#                                                       str(flag))\n",
    "#             im.save(filename)\n",
    "        else:\n",
    "            feature_obs = self.take_features(self.obs_camera)\n",
    "            rew = {self.low_level_agent_id: 0}\n",
    "            obs = {self.low_level_agent_id: feature_obs}\n",
    "            done[self.low_level_agent_id] = True\n",
    "            rew[\"high_level_agent\"] = -10*self.control_hla\n",
    "            obs[\"high_level_agent\"] = feature_obs\n",
    "            self.control_hla+=1\n",
    "            \n",
    "\n",
    "\n",
    "#         im = Image.fromarray(obs_lens)\n",
    "#         filename = self.filepath + \"\\img_%s_%s.png\" % (str(action_lens), \n",
    "#                                                            str(flag))\n",
    "#         im.save(filename)\n",
    "        \n",
    "        print('action:', action, 'info:',  done, rew)\n",
    "        return obs, rew, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return  BaslerEnv(env_config)\n",
    "\n",
    "register_env(\"BaslerEnv\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instant camera object with the camera device found first.\n",
    "# camera = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateFirstDevice())\n",
    "# camera.Open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models import ModelCatalog\n",
    "from ray import tune\n",
    "from ray.tune import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelCatalog.register_custom_model(\"PPO_2\",PPO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.zeros((404, 417, 3)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 11:55:59,436\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-03-25 11:56:01,376\tWARNING sample.py:404 -- DeprecationWarning: wrapping <function policy_mapping_fn at 0x000001EFC9459558> with tune.function() is no longer needed\n",
      "2021-03-25 11:56:01,427\tINFO trainer.py:616 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-03-25 11:56:01,429\tINFO trainer.py:643 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m WARNING:tensorflow:From C:\\Users\\CIG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m 417 404\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m 148\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m ---------------camera env init-------------------\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m eCOMCaspErr: 0 0\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m 417 404\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m 148\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m ---------------camera env init-------------------\r\n",
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m ---------------lens env init-------------------\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\CIG/.cache\\torch\\hub\\master.zip\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m \u001b[31m\u001b[1mrequirements:\u001b[0m dataclasses not found and is required by YOLOv5, attempting auto-update...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=21208)\u001b[0m ERROR: Invalid requirement: \"'dataclasses'\"\r\n"
     ]
    },
    {
     "ename": "RayTaskError(CalledProcessError)",
     "evalue": "\u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=21208, ip=10.16.102.19)\n  File \"C:\\Users\\CIG/.cache\\torch\\hub\\ultralytics_yolov5_master\\utils\\general.py\", line 105, in check_requirements\n    pkg.require(r)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\pkg_resources\\__init__.py\", line 884, in require\n    needed = self.resolve(parse_requirements(requirements))\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\pkg_resources\\__init__.py\", line 770, in resolve\n    raise DistributionNotFound(req, requirers)\npkg_resources.DistributionNotFound: The 'dataclasses' distribution was not found and is required by torch\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=21208, ip=10.16.102.19)\n  File \"python\\ray\\_raylet.pyx\", line 439, in ray._raylet.execute_task\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\worker.py\", line 176, in reraise_actor_init_error\n    raise self.actor_init_error\n  File \"python\\ray\\_raylet.pyx\", line 473, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 476, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 480, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 378, in __init__\n    self.env = _validate_env(env_creator(env_context))\n  File \"<ipython-input-6-e807b39c3357>\", line 4, in env_creator\n  File \"<ipython-input-5-93c9828f9caa>\", line 17, in __init__\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\torch\\hub.py\", line 370, in load\n    model = _load_local(repo_or_dir, model, *args, **kwargs)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\torch\\hub.py\", line 396, in _load_local\n    hub_module = import_module(MODULE_HUBCONF, hubconf_path)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\torch\\hub.py\", line 71, in import_module\n    spec.loader.exec_module(module)\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"C:\\Users\\CIG/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\", line 18, in <module>\n    check_requirements(Path(__file__).parent / 'requirements.txt', exclude=('pycocotools', 'thop'))\n  File \"C:\\Users\\CIG/.cache\\torch\\hub\\ultralytics_yolov5_master\\utils\\general.py\", line 109, in check_requirements\n    print(subprocess.check_output(f\"pip install '{e.req}'\", shell=True).decode())\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\subprocess.py\", line 411, in check_output\n    **kwargs).stdout\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\subprocess.py\", line 512, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command 'pip install 'dataclasses'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(CalledProcessError)\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8df9fc6d94f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# ray.init()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m# tune.run(MyTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPPOTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"BaslerEnv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;31m# results = tune.run(\"PPO\", config=config, stop=stop,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m#                    restore=r'C:\\Users\\CIG\\Documents\\MATLAB\\ppo_pic\\checkpoint-21')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mTrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         def _init(self, config: TrainerConfigDict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mlogger_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_logger_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\tune\\trainable.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, logger_creator)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0msetup_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msetup_time\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mSETUP_TIME_THRESHOLD\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mget_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m             \u001b[1;31m# Evaluation setup.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, config, env_creator)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mpolicy_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_policy_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 num_workers=self.config[\"num_workers\"])\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_plan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_plan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_plan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\u001b[0m in \u001b[0;36m_make_workers\u001b[1;34m(self, env_creator, validate_env, policy_class, config, num_workers)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mtrainer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             logdir=self.logdir)\n\u001b[0m\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mDeveloperAPI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, logdir, _setup)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 remote_spaces = ray.get(self.remote_workers(\n\u001b[0;32m     80\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforeach_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                     lambda p, pid: (pid, p.observation_space, p.action_space)))\n\u001b[0m\u001b[0;32m     82\u001b[0m                 spaces = {\n\u001b[0;32m     83\u001b[0m                     \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"original_space\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclient_mode_enabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_client_hook_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\worker.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   1454\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1457\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRayTaskError(CalledProcessError)\u001b[0m: \u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=21208, ip=10.16.102.19)\n  File \"C:\\Users\\CIG/.cache\\torch\\hub\\ultralytics_yolov5_master\\utils\\general.py\", line 105, in check_requirements\n    pkg.require(r)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\pkg_resources\\__init__.py\", line 884, in require\n    needed = self.resolve(parse_requirements(requirements))\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\pkg_resources\\__init__.py\", line 770, in resolve\n    raise DistributionNotFound(req, requirers)\npkg_resources.DistributionNotFound: The 'dataclasses' distribution was not found and is required by torch\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=21208, ip=10.16.102.19)\n  File \"python\\ray\\_raylet.pyx\", line 439, in ray._raylet.execute_task\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\worker.py\", line 176, in reraise_actor_init_error\n    raise self.actor_init_error\n  File \"python\\ray\\_raylet.pyx\", line 473, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 476, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 480, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 378, in __init__\n    self.env = _validate_env(env_creator(env_context))\n  File \"<ipython-input-6-e807b39c3357>\", line 4, in env_creator\n  File \"<ipython-input-5-93c9828f9caa>\", line 17, in __init__\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\torch\\hub.py\", line 370, in load\n    model = _load_local(repo_or_dir, model, *args, **kwargs)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\torch\\hub.py\", line 396, in _load_local\n    hub_module = import_module(MODULE_HUBCONF, hubconf_path)\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\site-packages\\torch\\hub.py\", line 71, in import_module\n    spec.loader.exec_module(module)\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"C:\\Users\\CIG/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\", line 18, in <module>\n    check_requirements(Path(__file__).parent / 'requirements.txt', exclude=('pycocotools', 'thop'))\n  File \"C:\\Users\\CIG/.cache\\torch\\hub\\ultralytics_yolov5_master\\utils\\general.py\", line 109, in check_requirements\n    print(subprocess.check_output(f\"pip install '{e.req}'\", shell=True).decode())\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\subprocess.py\", line 411, in check_output\n    **kwargs).stdout\n  File \"C:\\Users\\CIG\\Anaconda3\\envs\\corning\\lib\\subprocess.py\", line 512, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command 'pip install 'dataclasses'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "\n",
    "def policy_mapping_fn(agent_id):\n",
    "    if agent_id.startswith(\"low_level_\"):\n",
    "        return \"low_level_policy\"\n",
    "    else:\n",
    "        return \"high_level_policy\"\n",
    "    \n",
    "    \n",
    "stop = {\"training_iteration\": 2000,\n",
    "        \"timesteps_total\": 1000,\n",
    "        \"episode_reward_mean\": 0.0,}\n",
    "\n",
    "# policy, env, gamma=0.99, n_steps=128, ent_coef=0.01, \n",
    "# learning_rate=0.00025, vf_coef=0.5, \n",
    "# max_grad_norm=0.5, lam=0.95, \n",
    "# nminibatches=4, noptepochs=4, \n",
    "# cliprange=0.2, \n",
    "# cliprange_vf=None, \n",
    "# verbose=0, tensorboard_log=None, \n",
    "# _init_setup_model=True, \n",
    "# policy_kwargs=None, \n",
    "# full_tensorboard_log=False, seed=None, n_cpu_tf_sess=None\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"env\": BaslerEnv,\n",
    "    \"num_workers\": 1,\n",
    "    \"entropy_coeff\": 0.01,\n",
    "    \"rollout_fragment_length\": 128,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"sgd_minibatch_size\": 128,\n",
    "    \"lr\": 0.00025,#tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \n",
    "            \"high_level_policy\": (PPOTFPolicy, \n",
    "                                  Box(0, 255, (2048,)),#(len(np.zeros((404, 417, 3)).flatten()),)),\n",
    "                                  Discrete(148), \n",
    "                                  {\"gamma\": 0.99}),\n",
    "            \n",
    "            \"low_level_policy\": (PPOTFPolicy,\n",
    "                                 Box(0, 255, (2048,)),#(len(np.zeros((404, 417, 3)).flatten()),)),\n",
    "                                 MultiDiscrete([69, 99]), \n",
    "                                 {\"gamma\": 0.0}),\n",
    "            \n",
    "#             \"low_level_policy\": (PPOTFPolicy,\n",
    "#                                  Tuple([\n",
    "#                                      lens_env.observation_space,\n",
    "#                                      Discrete(148)\n",
    "#                                  ]), maze.action_space, {\n",
    "#                                      \"gamma\": 0.0\n",
    "#                                  }),\n",
    "        },\n",
    "        \"policy_mapping_fn\": function(policy_mapping_fn),\n",
    "    },\n",
    "    \"framework\": \"tf\",#\"torch\", #if args.torch else \"tf\",\n",
    "    # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "    \"num_gpus\": int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")),\n",
    "}\n",
    "\n",
    "#from ray.rllib.agents.trainer_template import build_trainer\n",
    "\n",
    "# <class 'ray.rllib.agents.trainer_template.MyCustomTrainer'>\n",
    "# MyTrainer = build_trainer(\n",
    "#     name=\"MyCustomTrainer\",\n",
    "#     default_policy=MyTFPolicy)\n",
    "\n",
    "# ray.init()\n",
    "# tune.run(MyTrainer\n",
    "trainer = ppo.PPOTrainer(env= \"BaslerEnv\", config=config)\n",
    "# results = tune.run(\"PPO\", config=config, stop=stop,  \n",
    "#                    restore=r'C:\\Users\\CIG\\Documents\\MATLAB\\ppo_pic\\checkpoint-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.restore(r'C:\\Users\\CIG\\ray_results\\PPO_BaslerEnv_2021-03-16_12-51-26e5ngm_aa\\checkpoint_21\\checkpoint-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # Perform one iteration of training the policy with PPO\\n\",\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "    print('-------', i, '-------')\n",
    "# #     print(evaluation_results)\n",
    "    if i % 80 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checkpoint = trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stop = {\n",
    "#     \"training_iteration\": 100,\n",
    "#     \"timesteps_total\": 1000,\n",
    "# }\n",
    "\n",
    "# results = tune.run(\"PPO\", stop=stop, config=config, checkpoint_freq=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=~/ray_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
