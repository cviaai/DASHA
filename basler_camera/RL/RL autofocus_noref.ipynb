{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import error\n",
    "from gym.utils import closer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pypylon import pylon\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ctypes import *\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "import glob\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from gym import error\n",
    "from gym.utils import closer\n",
    "from gym import spaces\n",
    "from pypylon import pylon\n",
    "import time\n",
    "from matplotlib import cm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imquality.brisque as brisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "env_closer = closer.Closer()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorningEnv(gym.Env):\n",
    "    \"\"\"The main OpenAI Gym class. It encapsulates an environment with\n",
    "    arbitrary behind-the-scenes dynamics. An environment can be\n",
    "    partially or fully observed.\n",
    "    The main API methods that users of this class need to know are:\n",
    "        step\n",
    "        reset\n",
    "        render\n",
    "        close\n",
    "        seed\n",
    "    And set the following attributes:\n",
    "        action_space: The Space object corresponding to valid actions\n",
    "        observation_space: The Space object corresponding to valid observations\n",
    "        reward_range: A tuple corresponding to the min and max possible rewards\n",
    "    Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.\n",
    "    The methods are accessed publicly as \"step\", \"reset\", etc...\n",
    "    \n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['rgb_array']}\n",
    "    \n",
    "    def __init__(self, file_path = r'D:\\RL_autofocus'):\n",
    "        \n",
    "        \n",
    "        # Create an instant camera object with the camera device found first.\n",
    "        self.camera = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateFirstDevice())\n",
    "        self.camera.Open()\n",
    "        self.camera.AcquisitionFrameRateAbs.Value = 10\n",
    "        self.camera.GainRaw.Value = 36\n",
    "        self.camera.ExposureTimeRaw.Value = 30000\n",
    "        self.camera.AcquisitionMode.SetValue('Continuous')\n",
    "        self.camera.Width.Value = 417\n",
    "        self.camera.Height.Value = 404\n",
    "        print(self.camera.Width.GetValue(), self.camera.Height.GetValue())\n",
    "        # code from https://github.com/basler/pypylon/blob/master/samples/opencv.py\n",
    "        img = pylon.PylonImage()\n",
    "        self.converter = pylon.ImageFormatConverter()\n",
    "        # converting to opencv bgr format\n",
    "        self.converter.OutputPixelFormat = pylon.PixelType_BGR8packed\n",
    "        self.converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned\n",
    "        \n",
    "        \n",
    "        # corning lib\n",
    "        self.lib = cdll.LoadLibrary(r\"C:\\Users\\CIG\\Documents\\MATLAB\\ComCasp64.dll\")\n",
    "        #Check if Maxim driver dll is loaded\n",
    "        eCOMCaspErr = getattr(self.lib,'Casp_OpenCOM')\n",
    "        print('eCOMCaspErr:', eCOMCaspErr(), self.lib.Casp_OpenCOM())\n",
    "        \n",
    "        \n",
    "        # yolo\n",
    "        self.model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', \n",
    "                                         force_reload=True, \n",
    "                                         pretrained=True)\n",
    "        \n",
    "        self.resnet152 = models.resnet152(pretrained=True)\n",
    "        modules=list(self.resnet152.children())[:-1]\n",
    "        self.resnet152=nn.Sequential(*modules)\n",
    "        for p in self.resnet152.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        self.action_space = spaces.MultiDiscrete([69, 99])\n",
    "        self.observation_space = spaces.Box(0, 2, (2048, ))\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.step_rem_at_level = 10\n",
    "        \n",
    "    def grab_image(self):\n",
    "        # https://github.com/basler/pypylon/blob/master/samples/opencv.py\n",
    "        self.camera.StartGrabbing()\n",
    "        while 1:\n",
    "            grabResult = self.camera.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)\n",
    "            if grabResult.GrabSucceeded():\n",
    "                # Access the image data\n",
    "                image = self.converter.Convert(grabResult)\n",
    "                image = image.GetArray()\n",
    "                #print(img[0])\n",
    "                #print('shape:', img.shape)\n",
    "                #plt.imshow(img)\n",
    "                break\n",
    "        self.camera.StopGrabbing()\n",
    "        return image\n",
    "        \n",
    "    def lens_movement(self, action):\n",
    "        x = c_double(action)\n",
    "        self.lib.Casp_SetFocusVoltage(x)\n",
    "        time.sleep(3)\n",
    "    \n",
    "    def find_class(self, results, obj = 'car'):\n",
    "        len_of_class = len(results.pred)\n",
    "        pred_class = [int(results.pred[0][i].numpy()[5]) for i in range(len(results.pred[0]))]\n",
    "        #list_of_yolo_classes = list(zip(results.names, range(0, len(results.names))))\n",
    "        pred_names = [results.names[i] for i in pred_class]\n",
    "        if obj in pred_names:\n",
    "            index = pred_names.index(obj)\n",
    "            return results.pred[0][index].numpy()\n",
    "        else:\n",
    "            return np.array([])\n",
    "        \n",
    "    def take_features(self, img):\n",
    "        preprocess = transforms.Compose([\n",
    "                            transforms.Resize(256),\n",
    "                            transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "        \n",
    "        image = Image.fromarray(np.uint8(img)).convert('RGB')\n",
    "        input_tensor = preprocess(image)\n",
    "        input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "        \n",
    "        # Run through the convolutional layers and resize the output.\n",
    "        features_output = self.resnet152(input_batch)\n",
    "        classifier_input = features_output.view(1, -1)\n",
    "        \n",
    "        return classifier_input.cpu().detach().numpy()[0]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment to an initial state and returns an initial\n",
    "        observation.\n",
    "        Note that this function should not reset the environment's random\n",
    "        number generator(s); random variables in the environment's state should\n",
    "        be sampled independently between multiple calls to `reset()`. In other\n",
    "        words, each call of `reset()` should yield an environment suitable for\n",
    "        a new episode, independent of previous episodes.\n",
    "        Returns:\n",
    "            observation (object): the initial observation.\n",
    "        \"\"\"\n",
    "        self.lens_movement(24.0)\n",
    "        observation = self.grab_image()\n",
    "        observation_feat = self.take_features(observation)\n",
    "        self.step_rem_at_level = 10\n",
    "        \n",
    "        #print(observation_feat)\n",
    "        #print(type(observation_feat), min(observation_feat), max(observation_feat), len(observation_feat))\n",
    "        \n",
    "        return observation_feat\n",
    "           \n",
    "    def step(self, action):\n",
    "        \"\"\"Run one timestep of the environment's dynamics. When end of\n",
    "        episode is reached, you are responsible for calling `reset()`\n",
    "        to reset this environment's state.\n",
    "        Accepts an action and returns a tuple (observation, reward, done, info).\n",
    "        Args:\n",
    "            action (object): an action provided by the agent\n",
    "        Returns:\n",
    "            observation (object): agent's observation of the current environment\n",
    "            reward (float) : amount of reward returned after previous action\n",
    "            done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n",
    "            info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
    "        \"\"\"\n",
    "        self.step_rem_at_level-=1\n",
    "        \n",
    "        if self.step_rem_at_level == 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        action_lens_coarse = 0\n",
    "        action_lens_fine = action[1]\n",
    "        if action[0] < 24:\n",
    "            action_lens_coarse = 24\n",
    "        else:\n",
    "            action_lens_coarse = action[0]\n",
    "        action_lens = float(\"%s.%s\"% (str(action_lens_coarse), str(action_lens_fine)))\n",
    "        print(action_lens)\n",
    "        \n",
    "        self.lens_movement(action_lens)\n",
    "        observation = self.grab_image()\n",
    "        observation_feat = self.take_features(observation)\n",
    "        \n",
    "        prediction_yolo = self.model_yolo(observation)\n",
    "        final_result_yolo = self.find_class(prediction_yolo)\n",
    "\n",
    "        brisque_score = -10\n",
    "        reward = brisque_score\n",
    "        \n",
    "        if final_result_yolo.size != 0:\n",
    "            image = Image.fromarray(observation)\n",
    "            image = image.crop((final_result_yolo[0], \n",
    "                             final_result_yolo[1], \n",
    "                             final_result_yolo[2], \n",
    "                             final_result_yolo[3]))\n",
    "            brisque_score = round(brisque.score(image), 2)\n",
    "            reward = - 0.01*brisque_score\n",
    "            done = True\n",
    "\n",
    "        im = Image.fromarray(observation)\n",
    "        file_path = r'D:'\n",
    "        filename = file_path + \"\\img_%s_%s.png\" % (str(action_lens), str(brisque_score))\n",
    "        im.save(filename)\n",
    "\n",
    "        print('reward:', reward)\n",
    "        return observation_feat, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return  CorningEnv(env_config)\n",
    "\n",
    "register_env(\"CorningEnv\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-27 14:07:17,980\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-04-27 14:07:20,038\tINFO trainer.py:616 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-04-27 14:07:20,040\tINFO trainer.py:643 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m WARNING:tensorflow:From c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 417 404\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m eCOMCaspErr: 0 0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\CIG/.cache\\torch\\hub\\master.zip\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m                  from  n    params  module                                  arguments                     \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m  24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m Model Summary: 283 layers, 7276605 parameters, 7276605 gradients, 17.1 GFLOPS\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m Adding autoShape... \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m YOLOv5  2021-4-27 torch 1.8.0+cpu CPU\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 2021-04-27 14:07:29,660\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-04-27 14:07:30,892\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-04-27 14:07:33,883\tINFO trainable.py:103 -- Trainable.setup took 13.845 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-04-27 14:07:33,883\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "config={\n",
    "        \"env\": CorningEnv,\n",
    "        \"num_workers\": 1,\n",
    "        \"entropy_coeff\": 0.01,\n",
    "        \"rollout_fragment_length\": 128,\n",
    "        \"train_batch_size\": 128,\n",
    "        \"sgd_minibatch_size\": 128,\n",
    "        \"lr\": 0.00025,#tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "        # Smooth metrics over this many episodes.\n",
    "        \"metrics_smoothing_episodes\": 10000,\n",
    "    }\n",
    "\n",
    "trainer = ppo.PPOTrainer(env= \"CorningEnv\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-27 14:07:33,973\tINFO trainable.py:372 -- Restored on 10.16.102.19 from checkpoint: C:\\Users\\CIG\\ray_results\\OnlyLens_nofer2\\checkpoint_34\\checkpoint-34\n",
      "2021-04-27 14:07:33,973\tINFO trainable.py:379 -- Current state after restoring: {'_iteration': 34, '_timesteps_total': None, '_time_total': 27849.84657382965, '_episodes_total': 2552}\n"
     ]
    }
   ],
   "source": [
    "trainer.restore(r'C:\\Users\\CIG\\ray_results\\OnlyLens_nofer2\\checkpoint_34\\checkpoint-34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 2021-04-27 14:07:37,753\tWARNING deprecation.py:34 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 48.25\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.149\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 47.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.1278\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 47.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.2389\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 47.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.1907\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 48.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.4191\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 47.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.0808\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 47.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m reward: -0.1085\n",
      "\u001b[2m\u001b[36m(pid=16856)\u001b[0m 47.18\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # Perform one iteration of training the policy with PPO\\n\",\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "    print('-------', i, '-------')\n",
    "# #     print(evaluation_results)\n",
    "    if i % 80 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6322\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.38180000000000003\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.5953\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6162\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.5427000000000001\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.35\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.3779\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.3911\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 24.18\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.40750000000000003\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.88\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4449\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6241\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4021\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6373\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4364\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.15\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.81\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6013000000000001\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.96\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.12\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6584000000000001\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6331\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6379\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.71\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.41500000000000004\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.3887\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.389\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.44070000000000004\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.5875\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.77\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4238\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.37950000000000006\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.3887\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6277\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4148\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.37229999999999996\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.2\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.84\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4033\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.4374\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.91\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.43060000000000004\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6537999999999999\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.38520000000000004\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.18\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -10\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.5735\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.7091\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.5566\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 47.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.42110000000000003\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m 48.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m c:\\users\\cig\\anaconda3\\envs\\rlautofocus\\lib\\site-packages\\imquality\\brisque.py:45: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\r\n",
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m   self.image = skimage.color.rgb2gray(self.image)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13380)\u001b[0m reward: -0.6111\r\n"
     ]
    }
   ],
   "source": [
    "checkpoint = trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=~/ray_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
